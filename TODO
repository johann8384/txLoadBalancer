Roadmap
=======

Bugs
----


Placeholders
------------
 * still missing a crucial piece in txlbWeb.tac: it's currently only showing
   how to start up a native web server; we need it to start up a proxy server
   that lb's to the proxied hosts
 * can nextHost() get unburried? How "close" can we bring it to the receiver
   factory?
 * look at iterating over service collections from inside the host checker
 * look at stopping and starting services from inside checker functions
 * look at the reason for bad host data to be stored on the scheduler
 * consider having the proxy manager manage bad hosts
 * consider creating proxy manager methods for starting and stopping services
   for bad hosts put back into and taken out of rotation
 * rename 'manager' attributes to 'taskManager'
 * rename 'director' attributes to 'proxyManager'


Version 1.1.0
-------------
 * fill in all docstrings (at the very least, for classes and module-level
   functions)
   . tx.proxy - DONE
   . tx.schedulers - DONE
   . tx.application - DONE
 * eliminate old methods (such as AdminUserConfig.checkAccess) that were part
   of the old API
 * add weighted host scheduler (use code from when I was at PBS)
 * add a configuration checker and write out the new ones to disk
   . back up the old ones
   . disable by default; add configuration option in manager
   . store initial configuration in memory as an unparsed string (for
     comparison)
 * add web admin UI support for enabling groups


Version 1.2.0
-------------
 * add a scheduler that accounts for memory and CPU utilization, which will
   require:
   . a standard python means for services to get system memory and other
     resource utilization stats
   . a means for services to report this to the ProxyManager
   . an algorigthm (or series of them) for determining the suitablity of a
     service to receive the next request based on a total evalution of current
     reported resource utilization
 * I don't like the default behaviour of adding bad hosts back into circulation
   without any checks; I want to add something there...
   . store away more info about the down hosts
   . when, how long til next test, etc.
 * sort service groups in admin UI by name
 * cache DNS lookups
 * start adding unit tests
 * support a configurable option to log connections to balanced servers


Version 1.3.0
-------------
 * add heartbeat/HA features for lb'ed services to communicate back up to the
   lb manager
 * add an XML-RPC service instead of the custom web API
   . including adding methods for bouncing the admin UI
 * replace old PyDirector logging with Twisted logging
 * figure out a way to restart/upgrade pydir. Idea: close down listener, start
   new code immediately
   . let old connections on old pydir finish (run to completion) before exiting
   . look at (again) JP's live process migration work from several years ago
 * add diffs for examining running/stored configurations
 * move CSS into a static file
 * continue adding unit tests


Version 1.4.0
-------------
 * [maybe] make the "top" link point to a list of service groups, linked to
   pages that just display that one section (as opposed to the view that
   "running" gives, which is all sections)
 * examine the benefits of schedulers having write control over host data
   . all that information is connection-oriented, and thogh the schedulers need
     that info, it is not part of their purpose: determining where the current
     request should be directed
   . connection information should be at the proxy level (the TCP server
     that opens connections to the proxied host)
   . proxies should track information for each of its connections (really, the
     connections being made to the proxy's receiver)
 * examine breaking out listeners and managers across different processes/hosts
   . if a Twisted service is to be loadbalanced how should that happen?
   . if we are running a manger daemon for twisted services that are configured
     to be loadbalanced, how should that happen?
   . what about all of the services potentially being equal? any can be a
     manager, any can be balanced via another services proxy manager
 * sticky connections. keep a cache of 'client_ip':'backend_ip'
   . manager needs to be able to call "scheduler.cleanup()" to allow the
     cache to be manageable.
 * continue adding unit tests


Version 1.5.0
-------------
 * convert the user auth to use cred
 * complete unit tests


Version 2.0.0
-------------
 * the AMP-based "bottle" protocol
 * messaging, process control
 * cluster management
 * add additional authentication support
   . LDAP
   . RADIUS
 * connection count scheduler
  . could be used to track licensing of a service, or limit it


Exploratory
-----------
 * develop a twisted.application API that can be used by other applications
   to load balancing
   . a service needs to indicate that it is load balancing
   . if it is, it needs to read its load balancing configuration object
   . it needs to start up one or more proxies
   . it needs shutdown its main service and replace it with a listening service
 * in order for this to happen, most of the responsiblities of the proxy
   manager need to move out into a t.a.service object
   . the following need to be managed: proxies, schedulers, connections, and
     configurations
 * likewise, connection tracking and managerment need to be taken out of the
   scheduler code and put into the service management code
   . the proxy should not access the scheduler directly, it should ask the
     proxy manager to do it on its behalf (by calling the appropriate pm
     method)
 * configuration-oriented methods need to be moved onto new objects in a module
   of the txlb.application sub package.
 * static load balancring service
   . number of proxies are determined by configuration
 * dynamic load balancing service
   . number of proxies are determined by load
   . need to define "load"
 * possibly add proxy mixins/subclasses for different protocols (HTTP, DNS,
   etc.)
 * add the ability to do auto-naming (auto-incrementing a counter) so that if a
   name is left out (or if a host is auto-detected) it has a default
 * ideas from Glyph about "stage 1" prototype:
   . make tbType an objhect
   . if you want to change the propertiess of the host that you load balance
     to something else, you need a way of doing this (I believe my model
     classes do just this)
   . the end user doesn't need to see the hierarchy of model relationships:
     give them an application-level mapper that displays cleanly and deduce
     structure from that
  . let's say you have a prod cluster and a test cluster, etc.:
